epoch,train_loss,val_loss
0,12200.5009765625,10818.302734375
1,10637.0126953125,10374.2783203125
2,10311.779296875,10145.2119140625
3,10140.462890625,10059.8857421875
4,10032.8505859375,9930.716796875
5,9949.0712890625,9926.8447265625
6,9887.8291015625,9875.947265625
7,9829.0693359375,9772.4912109375
8,9788.4814453125,9769.8701171875
9,9750.2802734375,9747.5712890625
10,9717.51953125,9730.9072265625
11,9690.0341796875,9633.6318359375
12,9663.60546875,9691.36328125
13,9643.1865234375,9632.2861328125
14,9624.3037109375,9636.072265625
15,9602.4052734375,9617.248046875
16,9585.326171875,9739.61328125
17,9569.87109375,9636.0234375
18,9552.818359375,9554.8623046875
19,9542.1279296875,9537.3115234375
